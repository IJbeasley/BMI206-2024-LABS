---
title: 'Lab 1: Linear models for quantitative genetics'
subtitle: "BMI 206"
author: "Isobel Beasley"
date: "Due: 18th October 20224"
output: html_document
---
<br>
<br>

## PART1: Analyzing provided genotype and phenotype data.

### __Prepare the data.__
### Read in the genotype and phenotype matrices. 
```{r}
genos = as.matrix(read.table(here::here("gwas/genos.txt")))
phenos = as.matrix(read.table(here::here("gwas/phenos.txt")))
```
<br>

### Make a histogram of the phenotypes. Do they look normally distributed?

```{r}
hist(phenos)
mean(phenos)
median(phenos)
```
<br>

Yes, the observed phenotypes appear to be roughly normally distributed, since we can observe in the above histogram: a single mode at about 0, which roughly corresponds to the mean (```round(mean(phenos), digits = 2)```), and data distributed roughly symmetrically about this mode (with perhaps the exception of a few left skewed values, but the mean and median values are still quite similar). 

Additionally, the tails of this distribution do not appear particularly 'fat', meaning the distribution is likely better approximated by a normal distribution than a t-distribution. 

### How are the genotypes encoded?
```{r}
table(genos)
```
The genotypes are encoded such that the heterozygous genotype for each snp is 1, the homogyzous genotypes are encoded as 2 or 0, depending on which allele is consider the reference at each locus.

<br>

### How many individuals are there in the dataset and how many SNPs? (Save them in `N` and `M`, respectively.)
```{r, eval=TRUE}
dim(genos)
dim(phenos)
N = length(phenos)
N # number of individuals
M = ncol(genos)
M # number of SNPs
```

<br>

### __Compute the *minor* allele frequency for every SNP. Check MAFs are <0.5.__

```{r, eval=TRUE}
MAFs = array(0,M)

for(i in 1:M) {
      MAFs[i] = sum(genos[,i]) / (2*N)
      
      # checking that MAF<0.5
      # if major allele freq was calculated, then 
      # take minor allele freq as 1-allele freq
      # if(MAFs[i]>0.5){
      #   MAFs[i] = 1-MAFs[i]
      # }
      
      MAFs[i] = min(MAFs[i], 1-MAFs[i])
      
}

# out of interest, this was the fastest approach I tried
# MAFs = colSums(genos) / (2*N)
# MAFs = ifelse(MAFs > 0.5, 1-MAFs, MAFs)

length(MAFs) # check that it was calculated for the right number of snps
MAFs[1:10] # how does the MAF look for the first 10 snps 
max(MAFs)
```
<br>

### __Run a GWAS under an additive model and save the p-values, z-scores, and effect sizes.__
```{r, eval=TRUE}

pvalues = array(0,M)
zscores = array(0,M)
betas = array(0,M)

for(i in 1:M) {
	g = genos[,i]
	# under an additive model means, without considering possible dominance / recessives
	res = summary(lm(phenos~g))
	zscores[i] = res$coefficients[2,"t value"]
	pvalues[i] = res$coefficients[2,"Pr(>|t|)"]
	betas[i] = res$coefficients[2,"Estimate"]
}
```
<br>

### Summarize the effect sizes.

```{r, eval=TRUE}
summary(betas)
hist(betas, breaks = 20, main = "Distribution of Estimated Effect sizes")
```
Most estimated effect sizes are close to zero (small, IQR range ~-0.1 to ~0.1). There seems to be a slight bias towards positive effect sizes (mean & median > 0). However, at a genome-wide level, negative effect sizes are roughly as common as positive effect sizes. The distribution of effect sizes appears to be roughly symmetric around zero. 

<br>

### Are there any significantly associated SNPs? If so, which SNPs are they?
```{r,eval=TRUE}
sig_thresh = 0.05 / M #bonferroni corrected significance test 
assoc = which(pvalues<sig_thresh)
assoc # the first 10 snps are the significantly associated snps
```
<br>

### How big are their effect sizes? How significant are they? 
```{r, eval=TRUE}
betas[assoc]
abs(betas[assoc]) # this is how big their effect sizes are
zscores[assoc] # zscores tell you about significance - but more importantly
pvalues[assoc] # the p-values tell you how significant they are ... pretty significant, all p-values are at least one order of magnitude smaller than the significance threshold (~5 * 10^-6)
# and most (8/9) significant p-values are at least 13 orders of magnitude smaller than the significance threshold
```
<br>

### Draw a QQ plot for log10(p) values.

```{r, eval=TRUE, fig.height = 9}
obsLogPvs = sort(-log10(pvalues))
expLogPvs = sort(-log10(seq(1/M,1,1/M)))
plot(expLogPvs,obsLogPvs,main='QQ plot')
abline( a=0, b=1 )
#label the significant SNPs red 
points(expLogPvs[(M-length(assoc)):M],obsLogPvs[(M-length(assoc)):M],col="red")
```
<br>

### Is there inflation? Use the chi-square statistics to check.
```{r, eval=TRUE}
chis = zscores^2
lambdaGC = median(chis)/0.454 # why .454?
# .454 =  qchisq(0.5, 1), the median of chisquared distribution with 1 degree of freedom (i.e. the median of null distribution)
lambdaGC
# this value is close to 1, suggestive of no inflation 
```
<br>

### Plot the phenotype predictions for the most significant SNP.
```{r, eval=TRUE}
topSNP = genos[,order(pvalues)[1]]
plot(topSNP,phenos)
abline(lm(phenos~topSNP)$coeff,col="red")
```
<br>

### __Build a linear predictor of the phenotype using the associated SNPs.__
```{r, eval=TRUE}
ypred = array(0,N)
# for each individual, predict their phenotypic score as the sum of their genotypes
# times the respective effect size calculated for that snp
for(i in 1:N) {
      ypred[i] = genos[i,assoc] %*% betas[assoc]
}
plot(ypred,phenos)
```
<br>

### What is the correlation between the predicted phenotype and the true phenotype?

```{r, eval=TRUE}
cor(ypred,phenos)
```
<br>

### __BONUS: Test each of the associated SNPs for non-linearity.__
```{r, eval=TRUE}

hp = array(0,length(assoc))

for (i in 1:length(assoc)) {
  g = genos[,assoc[i]]
  h = g
  h[h==2]=0 
  #Hint: can use anova(lm(?),lm(?)) or summary(lm(?))
  
  # ? not sure of the below approach I took: 
  # testing for whether there is any model performance difference between
  # the model where the only covariate is h (0, and 2 genotypes are combined into 0)
  # vs. the model with just an intercept term (sample mean) as predictor - 
  # the idea being if it is an additive model, the average of 
  # phenotypes of individuals with genotypes 0, 2 = average of phenotypes individual with genotype 1
  # ... but idk, I feel like there being an imbalanced number of individuals in each h group, might mess with the testing here
  hp[i] <- anova( lm(phenos~h), lm(phenos~1) )$Pr[2] #skip multiple test correction for now
}
hp 


for (i in 1:length(assoc)) {
  g = genos[,assoc[i]]
  h = g
  h[h==2]=0
  #Hint: can use anova(lm(?),lm(?)) or summary(lm(?))
  # ??? really not sure about this, testing against just intercept
  hp[i] <- anova( lm(phenos~h), lm(phenos~1) )$Pr[2] #skip multiple test correction for now
}
```
<br>

### BONUS: Visualize a linear SNP and a non-linear SNP.
```{r, eval=TRUE}

par(mfrow=c(1,2) )

# get linear snp
lin_snp = assoc[which(hp==max(hp))]

# plot linear snp
plot(genos[,lin_snp], phenos)
points( c(0,1,2), tapply(phenos,genos[,lin_snp], mean ), col=2, pch=16, cex=3 )
lines( c(0,1,2), tapply(phenos,genos[,lin_snp], mean ), col=2, lwd=2  )

# non-linear snp

# get non-linear snp
non_lin_snp = assoc[which(hp==min(hp))]

# plot non-linear snp
plot( genos[,non_lin_snp], phenos )
points( c(0,1,2), tapply(phenos, genos[,non_lin_snp], mean ), col=2, pch=16, cex=3 )
lines( c(0,1,2), tapply(phenos, genos[,non_lin_snp], mean ), col=2, lwd=2  )

```
<br>

### __Repeat the GWAS to test for recessive rather than additive genetic effects.__
```{r, eval=TRUE}

genos2 = genos
genos2[genos<2]=1 # ?? this sets 0,1 as 1 - but i'd be inclined to set 0,1 as 0, and 2 as 1. 
pvalues2 = array(0,M)
zscores2 = array(0,M)
betas2 = array(0,M)
for(i in 1:M) {
  g = genos2[,i]
  res = summary(lm(phenos~g))
  zscores2[i] = res$coefficients[2,"t value"]
  pvalues2[i] = res$coefficients[2,"Pr(>|t|)"]
  betas2[i] = res$coefficients[2,"Estimate"]
}

```
<br>

### __Are the same SNPs significant or not?__
```{r, eval=TRUE}

assoc2 = which(pvalues2<sig_thresh)
assoc2

setdiff(assoc2, assoc)
setdiff(assoc, assoc2)

```

Most of the same SNPs are significant; only the 10th SNP is no longer significant, and no extra SNPs are significant under a recessive model. 

<br>

### __How did the effect sizes change?__
```{r, eval=TRUE}
plot(betas,betas2)
```

Some effect sizes increased, others decreased, and others remained comparable between the two models. 

The SNPs with the largest effect sizes (>1, -1<) in the additive model had similar effect size estimates under the recessive models, which is consistent with the fact that most significant SNPs in the additive model were also significant in the recessive model. 

Some SNPs had estimated effect sizes under the additive model that were very small (~0), but the recessive model had the largest estimated effects (>4, <-4). Since these SNPs were not significant even in the recessive model, it seems likely for this model that lower power is confounding these results (leading to inaccurate effect size estimates and/or insufficient information to call these  SNPs significant). 

<br>

## PART2: Simulating genotypes with LD.

### __Establish some important simulation parameters.__
```{r, eval=TRUE}
N = 1000 #number of individuals
M = 30   #number of non-causal SNPs
gs = matrix(0,nrow=N,ncol=M)
```
<br>

### __Simulate a GWAS data set.__
#### First, simulate the causal variant.
```{r, eval=TRUE}
set.seed = (42) #set random seed so we all get the same numbers
MAF = 0.5
gC = rbinom(N,1,MAF) #causal variant

```
<br>

#### Then, simulate the phenotypes given the causal variant.
```{r, eval=TRUE}
beta = 0.3 #association of causal variant
pheno = gC*beta + rnorm(N) 
```
<br>

#### Generate 10 SNPS in tight LD with the causal SNP.

```{r, eval=TRUE}
rho = 0.9
for(i in 1:10) {
  idx = rbinom(N,1,rho)
  gs[,i]=gC*idx+rbinom(N,1,MAF)*(1-idx)
  # test they have the right LD empirically
  cat( 'Observed LD = ', cor( gs[,i], gC ), '\n' )
  
  # Bonus: prove they have the right LD theoretically

}


```
<br>

#### Do the same for 10 moderate LD partners (rho=0.6).
```{r,eval=TRUE}
rho = 0.6
for(i in 1:10) {
  idx = rbinom(N,1,rho)
  gs[,i+10]=gC*idx+rbinom(N,1,MAF)*(1-idx)
  # test they have the right LD empirically
  cat( 'Observed LD = ', cor( gs[,i+10], gC ), '\n' )
}
```
<br>

Do the same for 10 independent SNPs (rho=0).
```{r,eval=TRUE}
rho = 0
for(i in 1:10) {
  idx = rbinom(N,1,rho)
  gs[,i+20]=gC*idx+rbinom(N,1,MAF)*(1-idx)
  # test they have the right LD empirically
  cat( 'Observed LD = ', cor( gs[,i+20], gC ), '\n' )
}
```

### __Run GWAS on the causal variant. Then run GWAS on the other variants. Keep track of the zscores only.__
```{r,eval=TRUE}
zsC = summary(lm(pheno~gC))$coef[2,3]
zs = sapply( 1:M, function(i) summary(lm(pheno~gs[,i]))$coef[2,3] )
```
<br>

### Visualize the relationship between the mean z-scores at the tag SNPs and the z-score at the causal SNP.
```{r,eval=TRUE}
par( mfrow=c(2,2) )
breaks = hist(c(0,zsC,zs),plot=F)$breaks
hist(zs[1:10],breaks=breaks, col=1, main='LD partners')
abline(v=zsC)
hist(zs[11:20],breaks=breaks, col=2, main='Low-LD partner SNPs')
abline(v=zsC)
hist(zs[21:30],breaks=breaks, col=3, main='Independent SNPs')
abline(v=zsC)
```
<br>

### __BONUS: Perform LD score regression. First, calculate the LD scores. There should be M+1 of them.__
```{r, eval=TRUE}
# ? LD scores are: the sum the squared Pearson correlation coefficients (r²) of a given SNP with all other SNPs 
all_gs = cbind(gs, gC)
cor_mat = apply(all_gs, MARGIN = 2, function(geno) cor(geno, gs))
colSums(cor_mat^2 - 1)

ldscores = colSums(cor_mat^2 - 1)
ldscores 
length(ldscores) # M + 1 = 31 - correct number of ldscores
```
<br>

### BONUS: Visualize LD score regression.
```{r,eval=TRUE}

# chi squared test stat is zscore squared 
chis = c( zs, zsC )^2
plot(ldscores, chis, ylab=expression(chi^2) )
#test for inflation
lambdaGC = median(chis)/0.454
lambdaGC
```
<br>

### BONUS: Estimate heritability.
```{r,eval=TRUE}
adjust_chisq = chis - 1
summary( lm(adjust_chisq ~ ldscores))$coef[2,1] * M/N
```
<br>

### BONUS: What is the true heritability?
```{r, eval=TRUE}  
var(ldscores) / var(adjust_chisq)
```









